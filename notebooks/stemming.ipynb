{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/akali/projects\n"
     ]
    }
   ],
   "source": [
    "%cd \"../\"\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/akali/projects/model-trainer\n"
     ]
    }
   ],
   "source": [
    "# %cd \"./model-trainer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:25:33] Logging configured [generic_iterative_stemmer.utils.logging]\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from typing import Iterable, Tuple, List\n",
    "\n",
    "from generic_iterative_stemmer.training.stemming import Word2VecStemmingTrainer, FastTextStemmingTrainer  # noqa\n",
    "from generic_iterative_stemmer.utils import get_path, configure_logging\n",
    "\n",
    "configure_logging()\n",
    "\n",
    "\n",
    "def similarities_to_words(similarities: Iterable[Tuple[str, float]]) -> List[str]:\n",
    "    return [word for word, _ in similarities]\n",
    "\n",
    "\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "corpus_name = \"wiki-he-ft-150\"\n",
    "corpus_folder = get_path(corpus_name)\n",
    "trainer = FastTextStemmingTrainer.load_from_state_file(corpus_folder=corpus_folder)\n",
    "# trainer = Word2VecStemmingTrainer.load_from_state_file(corpus_folder=corpus_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_14931/49973641.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/projects/model-trainer/generic_iterative_stemmer/utils/logging.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     80\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     81\u001B[0m         \u001B[0mstart\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 82\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     83\u001B[0m         \u001B[0mfinish\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     84\u001B[0m         \u001B[0mdelta\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtimedelta\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mseconds\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfinish\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mstart\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/projects/model-trainer/generic_iterative_stemmer/training/stemming/stemming_trainer.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, save_stem_dict_when_done)\u001B[0m\n\u001B[1;32m    239\u001B[0m                 \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    240\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0msave_stem_dict_when_done\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 241\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave_stem_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    242\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    243\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mmeasure_time\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/projects/model-trainer/generic_iterative_stemmer/training/stemming/stemming_trainer.py\u001B[0m in \u001B[0;36msave_stem_dict\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    289\u001B[0m             \u001B[0mlog\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"No iterations completed, skipping save.\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    290\u001B[0m             \u001B[0;32mreturn\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 291\u001B[0;31m         \u001B[0mstem_dict\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcollect_complete_stem_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    292\u001B[0m         \u001B[0mmodel_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_model_path\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlast_completed_iteration_folder\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    293\u001B[0m         \u001B[0msave_stem_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstem_dict\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstem_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel_path\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmodel_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/projects/model-trainer/generic_iterative_stemmer/training/stemming/stemming_trainer.py\u001B[0m in \u001B[0;36mcollect_complete_stem_dict\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    276\u001B[0m             \u001B[0miteration_stem_dict\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstats\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"stem_dict\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    277\u001B[0m             \u001B[0mstem_dict\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miteration_stem_dict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 278\u001B[0;31m         \u001B[0mreduced_stem_dict\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mreduce_stem_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstem_dict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    279\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mreduced_stem_dict\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    280\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/projects/model-trainer/generic_iterative_stemmer/training/stemming/stem_dict_generator.py\u001B[0m in \u001B[0;36mreduce_stem_dict\u001B[0;34m(stem_dict)\u001B[0m\n\u001B[1;32m     90\u001B[0m     \u001B[0mreduced_dict\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mStemDict\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     91\u001B[0m     \u001B[0;32mwhile\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstem_dict\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 92\u001B[0;31m         \u001B[0mword_to_reduce\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstem_dict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     93\u001B[0m         \u001B[0m_reduce_iteration\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstem_dict\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstem_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreduced_dict\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mreduced_dict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mword_to_reduce\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mword_to_reduce\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     94\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mreduced_dict\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:25:46] Reducing stem dict of size 398492 [generic_iterative_stemmer.training.stemming.stem_generator]\n",
      "[17:27:31] Stem dict saved: ./data/wiki-he-ft-150/iter-6/model.kv.stem-dict.json. [generic_iterative_stemmer.models.stemmed_keyed_vectors]\n",
      "[17:27:31] loading KeyedVectors object from ./data/wiki-he-ft-150/iter-6/model.kv [gensim.utils]\n",
      "[17:27:31] loading vectors_vocab from ./data/wiki-he-ft-150/iter-6/model.kv.vectors_vocab.npy with mmap=None [gensim.utils]\n",
      "[17:27:31] loading vectors_ngrams from ./data/wiki-he-ft-150/iter-6/model.kv.vectors_ngrams.npy with mmap=None [gensim.utils]\n",
      "[17:27:31] setting ignored attribute vectors to None [gensim.utils]\n",
      "[17:27:31] setting ignored attribute buckets_word to None [gensim.utils]\n",
      "[17:27:39] FastTextKeyedVectors lifecycle event {'fname': './data/wiki-he-ft-150/iter-6/model.kv', 'datetime': '2022-01-28T17:27:39.280649', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.11.0-40-generic-x86_64-with-glibc2.29', 'event': 'loaded'} [gensim.utils]\n"
     ]
    }
   ],
   "source": [
    "trainer.save_stem_dict()\n",
    "model = trainer.get_stemmed_keyed_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[('מארינרמאדימ', 0.8884439468383789),\n ('הירח', 0.7569180727005005),\n ('אנשי-המאדימ', 0.7338298559188843),\n ('גשושית', 0.6993806958198547),\n ('הגשושית', 0.6755995154380798),\n ('מטאורואידימ', 0.6630820035934448),\n ('חלל', 0.6528779864311218),\n ('האסטרואיד', 0.6345564126968384),\n ('אסטרואיד', 0.6335639357566833),\n ('מטאורואיד', 0.6322200298309326)]"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"מאדימ\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:50:55] loading Word2Vec object from ./data/wiki-he-200/cbow.model [gensim.utils]\n",
      "[00:50:56] loading wv recursively from ./data/wiki-he-200/cbow.model.wv.* with mmap=None [gensim.utils]\n",
      "[00:50:56] loading vectors from ./data/wiki-he-200/cbow.model.wv.vectors.npy with mmap=None [gensim.utils]\n",
      "[00:50:57] loading syn1neg from ./data/wiki-he-200/cbow.model.syn1neg.npy with mmap=None [gensim.utils]\n",
      "[00:50:58] setting ignored attribute cum_table to None [gensim.utils]\n",
      "[00:51:07] Word2Vec lifecycle event {'fname': './data/wiki-he-200/cbow.model', 'datetime': '2022-01-28T00:51:07.470899', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.11.0-40-generic-x86_64-with-glibc2.29', 'event': 'loaded'} [gensim.utils]\n",
      "[00:51:07] word2vec model loaded [generic_iterative_stemmer.utils.loader]\n"
     ]
    }
   ],
   "source": [
    "# from generic_iterative_stemmer.utils import load_w2v_model\n",
    "#\n",
    "# model_path = get_path(\"wiki-he-200\", \"cbow.model\")\n",
    "# model = load_w2v_model(model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "data": {
      "text/plain": "[('גברמסקל', 0.623926043510437),\n ('גברא', 0.6175172328948975),\n ('גבר-אישה', 0.574849009513855),\n ('גבראה', 0.5686978697776794),\n ('גברט', 0.567768931388855),\n ('גברי', 0.5624161958694458),\n ('אישה', 0.5594735741615295),\n ('גברס', 0.5575984120368958),\n ('גברתי', 0.5562868118286133),\n ('שגבר', 0.5514994263648987)]"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"גבר\", topn=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance to expected 'זמרת' is: 0.0031436861027032137\n"
     ]
    },
    {
     "data": {
      "text/plain": "[('המלכה-האלמנה', 0.296379417181015),\n ('מלכין-מס', 0.2722456753253937),\n ('מלוכה', 0.26417994499206543),\n ('מלכותי', 0.26219820976257324),\n ('נסיכ', 0.26190268993377686),\n ('המלכה-העוצרת', 0.2604866623878479),\n ('אליזבת', 0.2589646577835083),\n ('מלכות', 0.2571811378002167),\n ('ממלכת', 0.2554100453853607),\n ('איזבל', 0.25307783484458923)]"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import ndarray, array, dot\n",
    "import numpy as np\n",
    "\n",
    "positive = [\"אישה\", \"מלכ\"]\n",
    "negative = [\"גבר\"]\n",
    "expected = \"זמרת\"\n",
    "\n",
    "v1 = sum(1 * model.get_vector(p) for p in positive)\n",
    "v1 += sum(-1 * model.get_vector(n) for n in negative)\n",
    "v2 = model.get_vector(expected)\n",
    "\n",
    "\n",
    "def cosine_similarity(x, y):\n",
    "    return (x @ y) / (np.linalg.norm(x) * np.linalg.norm(y))\n",
    "\n",
    "\n",
    "def most_similar_not_normalized(\n",
    "    kv, positive=None, negative=None, topn=50, clip_start=0, clip_end=None,\n",
    "    restrict_vocab=None, indexer=None, hint=None\n",
    "):\n",
    "    # add weights for each key, if not already present; default to 1.0 for positive and -1.0 for negative keys\n",
    "    positive = [\n",
    "        (item, 1.0) if isinstance(item, str) else item\n",
    "        for item in positive\n",
    "    ]\n",
    "    negative = [\n",
    "        (item, -1.0) if isinstance(item, str) else item\n",
    "        for item in negative\n",
    "    ]\n",
    "\n",
    "    # compute the weighted average of all keys\n",
    "    all_keys, mean = set(), []\n",
    "    for key, weight in positive + negative:\n",
    "        if isinstance(key, ndarray):\n",
    "            mean.append(weight * key)\n",
    "        else:\n",
    "            mean.append(weight * kv.get_vector(key, norm=True))\n",
    "            if kv.has_index_for(key):\n",
    "                all_keys.add(kv.get_index(key))\n",
    "    if not mean:\n",
    "        raise ValueError(\"cannot compute similarity with no input\")\n",
    "    mean = array(mean).mean(axis=0)\n",
    "    if indexer is not None and isinstance(topn, int):\n",
    "        return indexer.most_similar(mean, topn)\n",
    "\n",
    "    dists = dot(kv.vectors[clip_start:clip_end], mean) / kv.norms[clip_start:clip_end]\n",
    "    if not topn:\n",
    "        return dists\n",
    "    best = np.argsort(dists)[::-1][:topn + len(all_keys)]\n",
    "    # ignore (don't return) keys from the input\n",
    "    result = [\n",
    "        (kv.index_to_key[sim + clip_start], float(dists[sim]))\n",
    "        for sim in best if (sim + clip_start) not in all_keys\n",
    "    ]\n",
    "    return result[:topn]\n",
    "\n",
    "\n",
    "print(f\"Distance to expected '{expected}' is: {cosine_similarity(v1, v2)}\")\n",
    "most_similar_not_normalized(kv=model, positive=positive, negative=negative, topn=10, hint=expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.23598"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity(\"שס\", \"הרצוג\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[('ספרד-ירושלימ', 0.686131477355957),\n ('מיר-ירושלימ', 0.6790103912353516),\n ('ירושלים-יריחו', 0.6479797959327698),\n ('חורב-ירושלימ', 0.6376091837882996),\n ('יפו-ירושלימ', 0.6291233897209167)]"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=[\"ירושלימ\", \"גרמניה\"], negative=[\"ברלינ\"], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[('בריטניה', 0.8076131343841553),\n ('אנגליה', 0.8028486371040344),\n ('אירלנדבריטניה', 0.7821201682090759),\n ('אירלנד', 0.7421994209289551),\n ('סקוטלנד', 0.7418844103813171)]"
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=[\"לונדונ\", \"גרמניה\"], negative=[\"ברלינ\"], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[('השמש', 0.607936441898346),\n ('נווה-צדק', 0.5932590961456299),\n ('ירח', 0.5838311910629272),\n ('ירחי-שמשי', 0.5565984845161438),\n ('מצקר-הלוי', 0.5458218455314636)]"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=[\"שמש\", \"שבתאי\", \"צדק\"], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           word  cosine_similarity  association_similarity\n",
      "0   x גברמסקל x           0.623926                1.041177\n",
      "5      x גברי x           0.562416                1.013833\n",
      "10     x נערה x           0.527326                1.066127\n",
      "15    x מזדקנ x           0.485710                1.059941\n",
      "20    x קיפוד x           0.108084                1.003731\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base_word = \"גבר\"\n",
    "others = model.index_to_key[0:2000]\n",
    "similarities: list = model.most_similar(base_word, topn=20)\n",
    "\n",
    "\n",
    "def get_similarity(model, word):\n",
    "    return word, model.similarity(base_word, word)\n",
    "\n",
    "\n",
    "similarities.append(get_similarity(model, \"קיפוד\"))\n",
    "similarities.append(get_similarity(model, \"תפוח\"))\n",
    "similarities.append(get_similarity(model, \"קילו\"))\n",
    "similarities.append(get_similarity(model, \"פסיפס\"))\n",
    "\n",
    "\n",
    "def representative_distances(model, representative: str, others: List[str]):\n",
    "    return model.distances(representative, other_words=others)\n",
    "\n",
    "\n",
    "def association_similarity(w1: str, w2: str, others):\n",
    "    x1 = representative_distances(model, w1, others)\n",
    "    x2 = representative_distances(model, w2, others)\n",
    "    return (x1.T @ x2) / len(others)\n",
    "\n",
    "\n",
    "records = []\n",
    "for similar_word, grade in similarities:\n",
    "    association = association_similarity(base_word, similar_word, others)\n",
    "    record = (f\"x {similar_word} x\", grade, association)\n",
    "    records.append(record)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=records, columns=[\"word\", \"cosine_similarity\", \"association_similarity\"]\n",
    ")\n",
    "\n",
    "print(df.sort_values(\"cosine_similarity\", ascending=False)[::5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('model-trainer': venv)",
   "language": "python",
   "name": "python3810jvsc74a57bd06e8222c86223522c750cbbc2c96d298f9dfae65b40cd1567f83c74c61183bce8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}