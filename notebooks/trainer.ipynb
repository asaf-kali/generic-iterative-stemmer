{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/akali/projects/model-trainer\n"
     ]
    }
   ],
   "source": [
    "% cd \"../\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/akali/projects/model-trainer\n"
     ]
    }
   ],
   "source": [
    "# %cd \"model-trainer\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:35:14] Logging configured [generic_iterative_stemmer.utils.logging]\n"
     ]
    }
   ],
   "source": [
    "from generic_iterative_stemmer.training.base import fast_text\n",
    "from generic_iterative_stemmer.training.base import word2vec\n",
    "from generic_iterative_stemmer.utils import get_path, configure_logging\n",
    "\n",
    "configure_logging()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "corpus_name = \"wiki-he-200\"\n",
    "corpus_file_path = get_path(corpus_name, \"corpus.txt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:35:19] Word2Vec lifecycle event {'params': 'Word2Vec(vocab=0, vector_size=200, alpha=0.025)', 'datetime': '2022-01-23T02:35:19.526950', 'gensim': '4.1.2', 'python': '3.8.10 (default, Sep 28 2021, 16:10:42) \\n[GCC 9.3.0]', 'platform': 'Linux-5.11.0-40-generic-x86_64-with-glibc2.29', 'event': 'created'} [gensim.utils]\n",
      "[02:35:19] collecting all words and their counts [gensim.models.word2vec]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/wiki-he-200/corpus.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[0;32m~/projects/venvs/model-trainer/lib/python3.8/site-packages/gensim/models/word2vec.py:2081\u001B[0m, in \u001B[0;36mLineSentence.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   2078\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   2079\u001B[0m     \u001B[38;5;66;03m# Assume it is a file-like object and try treating it as such\u001B[39;00m\n\u001B[1;32m   2080\u001B[0m     \u001B[38;5;66;03m# Things that don't have seek will trigger an exception\u001B[39;00m\n\u001B[0;32m-> 2081\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msource\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mseek\u001B[49m(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m   2082\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m itertools\u001B[38;5;241m.\u001B[39mislice(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msource, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlimit):\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'str' object has no attribute 'seek'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m w2v_cbow_output_path \u001B[38;5;241m=\u001B[39m get_path(corpus_name, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcbow\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m cbow_model \u001B[38;5;241m=\u001B[39m \u001B[43mword2vec\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcorpus_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcorpus_file_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_model_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mw2v_cbow_output_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvector_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m200\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\n\u001B[1;32m      7\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/model-trainer/generic_iterative_stemmer/training/base/word2vec.py:31\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(corpus_path, output_model_path, skip_gram, vector_size, window, min_count, epochs, **kwargs)\u001B[0m\n\u001B[1;32m     21\u001B[0m sg \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m skip_gram \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     22\u001B[0m model \u001B[38;5;241m=\u001B[39m Word2Vec(\n\u001B[1;32m     23\u001B[0m     sg\u001B[38;5;241m=\u001B[39msg,  \u001B[38;5;66;03m# 0=CBOW , 1=SkipGram\u001B[39;00m\n\u001B[1;32m     24\u001B[0m     vector_size\u001B[38;5;241m=\u001B[39mvector_size,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     29\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m     30\u001B[0m )\n\u001B[0;32m---> 31\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild_vocab\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcorpus_iterable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msentences\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain(corpus_iterable\u001B[38;5;241m=\u001B[39msentences, total_examples\u001B[38;5;241m=\u001B[39mmodel\u001B[38;5;241m.\u001B[39mcorpus_count, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m)\n\u001B[1;32m     33\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWord2Vec training done.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/projects/venvs/model-trainer/lib/python3.8/site-packages/gensim/models/word2vec.py:487\u001B[0m, in \u001B[0;36mWord2Vec.build_vocab\u001B[0;34m(self, corpus_iterable, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001B[0m\n\u001B[1;32m    449\u001B[0m \u001B[38;5;124;03m\"\"\"Build vocabulary from a sequence of sentences (can be a once-only generator stream).\u001B[39;00m\n\u001B[1;32m    450\u001B[0m \n\u001B[1;32m    451\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    484\u001B[0m \n\u001B[1;32m    485\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    486\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_corpus_sanity(corpus_iterable\u001B[38;5;241m=\u001B[39mcorpus_iterable, corpus_file\u001B[38;5;241m=\u001B[39mcorpus_file, passes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m--> 487\u001B[0m total_words, corpus_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscan_vocab\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcorpus_iterable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcorpus_iterable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcorpus_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcorpus_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprogress_per\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_per\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrim_rule\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrim_rule\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcorpus_count \u001B[38;5;241m=\u001B[39m corpus_count\n\u001B[1;32m    490\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcorpus_total_words \u001B[38;5;241m=\u001B[39m total_words\n",
      "File \u001B[0;32m~/projects/venvs/model-trainer/lib/python3.8/site-packages/gensim/models/word2vec.py:582\u001B[0m, in \u001B[0;36mWord2Vec.scan_vocab\u001B[0;34m(self, corpus_iterable, corpus_file, progress_per, workers, trim_rule)\u001B[0m\n\u001B[1;32m    579\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m corpus_file:\n\u001B[1;32m    580\u001B[0m     corpus_iterable \u001B[38;5;241m=\u001B[39m LineSentence(corpus_file)\n\u001B[0;32m--> 582\u001B[0m total_words, corpus_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_scan_vocab\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcorpus_iterable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprogress_per\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrim_rule\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    584\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\n\u001B[1;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcollected \u001B[39m\u001B[38;5;132;01m%i\u001B[39;00m\u001B[38;5;124m word types from a corpus of \u001B[39m\u001B[38;5;132;01m%i\u001B[39;00m\u001B[38;5;124m raw words and \u001B[39m\u001B[38;5;132;01m%i\u001B[39;00m\u001B[38;5;124m sentences\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    586\u001B[0m     \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw_vocab), total_words, corpus_count\n\u001B[1;32m    587\u001B[0m )\n\u001B[1;32m    589\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m total_words, corpus_count\n",
      "File \u001B[0;32m~/projects/venvs/model-trainer/lib/python3.8/site-packages/gensim/models/word2vec.py:551\u001B[0m, in \u001B[0;36mWord2Vec._scan_vocab\u001B[0;34m(self, sentences, progress_per, trim_rule)\u001B[0m\n\u001B[1;32m    549\u001B[0m vocab \u001B[38;5;241m=\u001B[39m defaultdict(\u001B[38;5;28mint\u001B[39m)\n\u001B[1;32m    550\u001B[0m checked_string_types \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m--> 551\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m sentence_no, sentence \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(sentences):\n\u001B[1;32m    552\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m checked_string_types:\n\u001B[1;32m    553\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(sentence, \u001B[38;5;28mstr\u001B[39m):\n",
      "File \u001B[0;32m~/projects/venvs/model-trainer/lib/python3.8/site-packages/gensim/models/word2vec.py:2090\u001B[0m, in \u001B[0;36mLineSentence.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   2087\u001B[0m             i \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_sentence_length\n\u001B[1;32m   2088\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m:\n\u001B[1;32m   2089\u001B[0m     \u001B[38;5;66;03m# If it didn't work like a file, use it as a string filename\u001B[39;00m\n\u001B[0;32m-> 2090\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msource\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m fin:\n\u001B[1;32m   2091\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m itertools\u001B[38;5;241m.\u001B[39mislice(fin, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlimit):\n\u001B[1;32m   2092\u001B[0m             line \u001B[38;5;241m=\u001B[39m utils\u001B[38;5;241m.\u001B[39mto_unicode(line)\u001B[38;5;241m.\u001B[39msplit()\n",
      "File \u001B[0;32m~/projects/venvs/model-trainer/lib/python3.8/site-packages/smart_open/smart_open_lib.py:188\u001B[0m, in \u001B[0;36mopen\u001B[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, compression, transport_params)\u001B[0m\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m transport_params \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    186\u001B[0m     transport_params \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m--> 188\u001B[0m fobj \u001B[38;5;241m=\u001B[39m \u001B[43m_shortcut_open\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    189\u001B[0m \u001B[43m    \u001B[49m\u001B[43muri\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    190\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    191\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    192\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbuffering\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbuffering\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    193\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    194\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    195\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnewline\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    196\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fobj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    198\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fobj\n",
      "File \u001B[0;32m~/projects/venvs/model-trainer/lib/python3.8/site-packages/smart_open/smart_open_lib.py:361\u001B[0m, in \u001B[0;36m_shortcut_open\u001B[0;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001B[0m\n\u001B[1;32m    358\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m    359\u001B[0m     open_kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124merrors\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m errors\n\u001B[0;32m--> 361\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_builtin_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocal_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffering\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbuffering\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mopen_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: './data/wiki-he-200/corpus.txt'"
     ]
    }
   ],
   "source": [
    "w2v_cbow_output_path = get_path(corpus_name, \"cbow\")\n",
    "cbow_model = word2vec.train(\n",
    "    corpus_path=corpus_file_path,\n",
    "    output_model_path=w2v_cbow_output_path,\n",
    "    vector_size=200,\n",
    "    epochs=10\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ft_output_path = get_path(corpus_name, \"ft\")\n",
    "fast_text.train(\n",
    "    corpus_path=corpus_file_path,\n",
    "    output_model_path=w2v_cbow_output_path,\n",
    "    vector_size=200,\n",
    "    epochs=10\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e8222c86223522c750cbbc2c96d298f9dfae65b40cd1567f83c74c61183bce8"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}